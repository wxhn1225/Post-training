## 值得参考的2个PPT

+ [ChatGPT + Post-Training](https://docs.google.com/presentation/d/11KWCKUORnPpVMSY6vXgBeFSWo7fJcuGQ9yuR6vC1pzE)
+ [The state of post-training](https://docs.google.com/presentation/d/1FL6pzRT3tjCfJ985emS_2YfujCe_iz6dsyRcDIUFPqs)


## 资料途径
+ 百度、bing
+ B站、YouTube
  + https://www.bilibili.com/video/BV1fJciefEq3
+ GitHub
  + https://github.com/mbzuai-oryx/Awesome-LLM-Post-training
+ https://www.interconnects.ai/
+ https://magazine.sebastianraschka.com/
+ 论坛
  + https://x.com/NandoDF/articles


## Post-training History

```mermaid
graph LR
    A(RLHF)-->B(???)
```

## 当前问题
+ RL、RLHF、Post-training的关系
+ RLHF和具体算法（例如：PPO之类的）的关系


## 参考论文


## RL基础
+ 视频
    + https://www.boyuai.com/elites/course/xVqhU42F5IDky94x   （暂不推荐）
    + B站：动手学强化学习（暂不推荐）、强化学习的数学原理
+ 文本
    + https://hrl.boyuai.com/          （暂不推荐）
    + https://github.com/MathFoundationRL/Book-Mathematical-Foundation-of-Reinforcement-Learning

动手学强化学习，还没开始看，看完再给评价。
